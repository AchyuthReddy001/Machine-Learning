q()
#importing dataset
data=read.csv("Position_Salaries.csv")
data=data[2:3]
#installing lib
install.packages("e1071")
library("e1071")
#building the model
reg=svm(formula=Salary ~ .,data = data,
type="eps-regression")
#predicting
y_pred=predict(reg,newdata = data.frame(Level=6.5))
#visualising the data
library(ggplot2)
ggplot()+
geom_point(aes(x=data$Level,y=data$Salary),color="blue")+
geom_line(aes(x=data$Level,y=predict(reg,newdata = data)),color="black")+
ggtitle("Sal vs Exp using SVR")+
xlab("Exp")+
ylab("Salary")
#importing dataset
data=read.csv("Position_Salaries.csv")
data=data[2:3]
#installing lib
install.packages("e1071")
library("e1071")
#building the model
reg=svm(formula=Salary ~ .,data = data,
type="eps-regression")
install.packages("e1071")
#building the model
reg=svm(formula=Salary ~ .,data = data,
type="eps-regression")
#importing dataset
data=read.csv("Position_Salaries.csv")
data=data[2:3]
#importing dataset
data=read.csv("Position_Salaries.csv")
data=data[2:3]
data=read.csv("Position_Salaries.csv")
#importing dataset
data=read.csv("Position_Salaries.csv")
data=data[2:3]
data=data[2:3]
#importing dataset
data=read.csv("Position_Salaries.csv")
#importing dataset
data=read.csv("E:\\MY_GOAL\\Machine Learning\\Part 2 - Regression\\Section 7 - Support Vector Regression (SVR)\\Position_Salaries.csv")
data=data[2:3]
data
View(data)
View(data)
#installing lib
install.packages("e1071")
library("e1071")
#building the model
reg=svm(formula=Salary ~ .,data = data,
type="eps-regression")
predicting
y_pred=predict(reg,newdata = data.frame(Level=6.5))
#visualising the data
library(ggplot2)
ggplot()+
geom_point(aes(x=data$Level,y=data$Salary),color="blue")+
geom_line(aes(x=data$Level,y=predict(reg,newdata = data)),color="black")+
ggtitle("Sal vs Exp using SVR")+
xlab("Exp")+
ylab("Salary")
getwd
setwd("E:/MY_GOAL/Machine Learning/Part 3 - Classification/Section 20 - Random Forest Classification")
#importingdata
data=read.csv("Social_Network_Ads.csv")
dataset=data[,3:5]
#importingdata
data=read.csv("Social_Network_Ads.csv")
dataset=data[,3:5]
#encoding target var
dataset$Purchased=factor(dataset$Purchased,levels = c(0,1))
#splitting data
set.seed(123)
#library(caTools)
split=sample.split(dataset$Purchased,SplitRatio = 0.75)
train_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
#feature scale
train_set[,1:2]=scale(train_set[,1:2])
test_set[,1:2]=scale(test_set[,1:2])
#build the model and test the model
install.packages('randomForest')
#importingdata
data=read.csv("Social_Network_Ads.csv")
dataset=data[,3:5]
#encoding target var
dataset$Purchased=factor(dataset$Purchased,levels = c(0,1))
#splitting data
set.seed(123)
#library(caTools)
split=sample.split(dataset$Purchased,SplitRatio = 0.75)
train_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
#feature scale
train_set[,1:2]=scale(train_set[,1:2])
test_set[,1:2]=scale(test_set[,1:2])
#build the model and test the model
install.packages('randomForest')
#importingdata
data=read.csv("Social_Network_Ads.csv")
dataset=data[,3:5]
#encoding target var
dataset$Purchased=factor(dataset$Purchased,levels = c(0,1))
#splitting data
set.seed(123)
#library(caTools)
split=sample.split(dataset$Purchased,SplitRatio = 0.75)
train_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
#feature scale
train_set[,1:2]=scale(train_set[,1:2])
test_set[,1:2]=scale(test_set[,1:2])
#importingdata
data=read.csv("Social_Network_Ads.csv")
dataset=data[,3:5]
#encoding target var
dataset$Purchased=factor(dataset$Purchased,levels = c(0,1))
#splitting data
set.seed(123)
#library(caTools)
split=sample.split(dataset$Purchased,SplitRatio = 0.75)
train_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
#feature scale
train_set[,1:2]=scale(train_set[,1:2])
test_set[,1:2]=scale(test_set[,1:2])
#importingdata
data=read.csv("Social_Network_Ads.csv")
dataset=data[,3:5]
#encoding target var
dataset$Purchased=factor(dataset$Purchased,levels = c(0,1))
#splitting data
set.seed(123)
#library(caTools)
split=sample.split(dataset$Purchased,SplitRatio = 0.75)
#splitting data
set.seed(123)
library(caTools)
split=sample.split(dataset$Purchased,SplitRatio = 0.75)
train_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
#feature scale
train_set[,1:2]=scale(train_set[,1:2])
test_set[,1:2]=scale(test_set[,1:2])
library(randomForest)
classifier=randomForest(x=train_set[-3],
y=train_set$Purchased,
ntree = 10)
y_pred=predict(classifier,newdata =test_set[-3])
cm=table(test_set[,3],y_pred)
cm
library(ElemStatLearn)
set = train_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, type = 'response', newdata = grid_set)
plot(set[, -3],
main = 'Random Forest Classification (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, type = 'response', newdata = grid_set)
plot(set[, -3],
main = 'Random Forest Classification (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
#ploting DTC
plot(classifier)
text(classifier)
#importingdata
data=read.csv("Social_Network_Ads.csv")
dataset=data[,3:5]
#encoding target var
dataset$Purchased=factor(dataset$Purchased,levels = c(0,1))
#splitting data
set.seed(123)
library(caTools)
split=sample.split(dataset$Purchased,SplitRatio = 0.75)
train_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
#feature scale
train_set[,1:2]=scale(train_set[,1:2])
test_set[,1:2]=scale(test_set[,1:2])
#build the model and test the model
library(e1071)
#build the model and test the model
library(e1071)
classifier=naiveBayes(x=train_set[-3],
y=train_set$Purchased)
#prediction
y_pred=predict(classifier,newdata =test_set[-3])
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#confusion matrix
cm=table(test_set[,3],y_pred)
cm
library(ElemStatLearn)
set = train_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.1)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, type = 'response', newdata = grid_set)
plot(set[, -3],
main = 'Naive Bayes(Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Training set results
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = train_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, type = 'response', newdata = grid_set)
plot(set[, -3],
main = 'Naive Bayes(Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = train_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier,newdata = grid_set)
plot(set[, -3],
main = 'Kernel_SVM (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid =predict(classifier,newdata = grid_set)
plot(set[, -3],
main = 'Kernel_SVM(Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("E:/MY_GOAL/Machine Learning/Part 4 - Clustering/Section 24 - K-Means Clustering")
#import data
data=read.csv("Mall_Customers.csv")
X=data[,3:4]
View(X)
View(data)
#import data
data=read.csv("Mall_Customers.csv")
X=data[,4:5]
View(X)
#Using ElBow method
set.seed(6)
wcss=vector()
for (i in 1:10) wcss=sum(kmeans(X,i)$withinss)
plot(1:10,wcss,type='b',main=paste("Elbow Method"),xlab = "No oF Clusters",
ylab = "WCSS")
#Using ElBow method
set.seed(6)
wcss=vector()
for (i in 1:10) wcss[i]=sum(kmeans(X,i)$withinss)
plot(1:10,wcss,type='b',main=paste("Elbow Method"),xlab = "No oF Clusters",
ylab = "WCSS")
#model build
set.seed(22)
km=kmeans(X,5,iter.max = 300,nstart = 10)
#visualising the clusters
library(cluster)
clusplot(X,
km$cluster,
lines=0,
shade=TRUE,
color=TRUE,
labels=2,
plotchar=FALSE,
span=TRUE,
main=paste("KMeans Cluster Alg"),
xlab="Annaul Income",
ylab="SpendingScore")
#import data
data=read.csv("Mall_Customers.csv")
X=data[,4:5]
#Using ElBow method
set.seed(6)
wcss=vector()
for (i in 1:10) wcss[i]=sum(kmeans(X,i)$withinss)
plot(1:10,wcss,type='b',main=paste("Elbow Method"),xlab = "No oF Clusters",
ylab = "WCSS")
#model build
set.seed(22)
km=kmeans(X,6,iter.max = 300,nstart = 10)
#visualising the clusters
library(cluster)
clusplot(X,
km$cluster,
lines=0,
shade=TRUE,
color=TRUE,
labels=2,
plotchar=FALSE,
span=TRUE,
main=paste("KMeans Cluster Alg"),
xlab="Annaul Income",
ylab="SpendingScore")
#import data
data=read.csv("Mall_Customers.csv")
X=data[,4:5]
#Using ElBow method
set.seed(6)
wcss=vector()
for (i in 1:10) wcss[i]=sum(kmeans(X,i)$withinss)
plot(1:10,wcss,type='b',main=paste("Elbow Method"),xlab = "No oF Clusters",
ylab = "WCSS")
#model build
set.seed(22)
km=kmeans(X,7,iter.max = 300,nstart = 10)
#visualising the clusters
library(cluster)
clusplot(X,
km$cluster,
lines=0,
shade=TRUE,
color=TRUE,
labels=2,
plotchar=FALSE,
span=TRUE,
main=paste("KMeans Cluster Alg"),
xlab="Annaul Income",
ylab="SpendingScore")
#import data
data=read.csv("Mall_Customers.csv")
X=data[,4:5]
#Using ElBow method
set.seed(6)
wcss=vector()
for (i in 1:10) wcss[i]=sum(kmeans(X,i)$withinss)
plot(1:10,wcss,type='b',main=paste("Elbow Method"),xlab = "No oF Clusters",
ylab = "WCSS")
#model build
set.seed(22)
km=kmeans(X,3,iter.max = 300,nstart = 10)
#visualising the clusters
library(cluster)
clusplot(X,
km$cluster,
lines=0,
shade=TRUE,
color=TRUE,
labels=2,
plotchar=FALSE,
span=TRUE,
main=paste("KMeans Cluster Alg"),
xlab="Annaul Income",
ylab="SpendingScore")
#import data
data=read.csv("Mall_Customers.csv")
X=data[,4:5]
#Using ElBow method
set.seed(6)
wcss=vector()
for (i in 1:10) wcss[i]=sum(kmeans(X,i)$withinss)
plot(1:10,wcss,type='b',main=paste("Elbow Method"),xlab = "No oF Clusters",
ylab = "WCSS")
#model build
set.seed(22)
km=kmeans(X,5,iter.max = 300,nstart = 10)
#visualising the clusters
library(cluster)
clusplot(X,
km$cluster,
lines=0,
shade=TRUE,
color=TRUE,
labels=2,
plotchar=FALSE,
span=TRUE,
main=paste("KMeans Cluster Alg"),
xlab="Annaul Income",
ylab="SpendingScore")
